{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수형 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor) # 입력과 출력 텐서를 지정하여 Model 클래스의 객체를 만듦\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 13.5801\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 15.2674\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 17.8119\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 21.1986\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 25.2148\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 29.4679\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 34.0552\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 39.0760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 44.1780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 49.8643\n",
      "1000/1000 [==============================] - 0s 60us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000,64))\n",
    "y_train = np.random.random((1000,10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중 입력 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 입력을 가진 질문-응답 모델의 함수형 API 구현하기\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# 텍스트 입력은 길이가 정해지지 않은 정수 시퀀스 / 입력 이름을 지정할 수 있음\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "# 입력을 크기가 64인 벡터의 시퀀스로 임베딩\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "# LSTM을 사용하여 이 벡터들을 하나의 벡터로 인코딩\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# 질문도 동일한 과정을 거치지만 층 객체는 다름\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# 인코딩된 질문과 텍스트를 연결\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "# 소프트맥스 분류기를 추가함\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "# 모델 객체를 만들고 2개의 입력과 출력을 주입\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 6.2141 - acc: 0.0020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 6.1927 - acc: 0.0310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 995us/step - loss: 6.1125 - acc: 0.0030\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 6.0281 - acc: 0.0060\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 957us/step - loss: 5.9650 - acc: 0.0080\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 957us/step - loss: 5.8972 - acc: 0.0130\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 994us/step - loss: 5.8239 - acc: 0.0140\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 962us/step - loss: 5.7472 - acc: 0.0180\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 950us/step - loss: 5.6483 - acc: 0.0260\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 5.5798 - acc: 0.0290\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 5.5029 - acc: 0.0470\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 5.4049 - acc: 0.0540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 991us/step - loss: 5.3635 - acc: 0.0540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 944us/step - loss: 5.2689 - acc: 0.0710\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 947us/step - loss: 5.2186 - acc: 0.0870\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 976us/step - loss: 5.1514 - acc: 0.0900\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 945us/step - loss: 5.0868 - acc: 0.0850\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 948us/step - loss: 5.0174 - acc: 0.0930\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 972us/step - loss: 4.9824 - acc: 0.0960\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 4.9067 - acc: 0.1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2354a262710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 입력 모델에 데이터 주입하기\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# 랜덤한 넘파이 데이터를 생성\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "answers = to_categorical(answers) # 답은 정수가 아닌 원-핫 인코딩된 벡터\n",
    "\n",
    "# 리스트 입력을 사용하여 학습\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# 딕셔너리 입력을 사용하여 학습 (입력 이름을 지정했을 때만 사용할 수 있음)\n",
    "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중 출력 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 출력을 가진 함수형 API 구현하기\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128,5,activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256,5,activation='relu')(x)\n",
    "x = layers.Conv1D(256,5,activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256,5,activation='relu')(x)\n",
    "x = layers.Conv1D(256,5,activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x) # 출력 층에 이름을 지정\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 출력 모델의 컴파일 옵션: 다중 손실\n",
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "# 위와 동일 (출력 층에 이름을 지정했을 때만 사용할 수 있음)\n",
    "model.compile(optimizer='rmsprop', loss={'age': 'mse', 'income': 'categorical_crossentropy', 'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 출력 모델의 컴파일 옵션: 손실 가중치\n",
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "# 위와 동일 (출력 층에 이름을 지정했을 때만 사용할 수 있음)\n",
    "model.compile(optimizer='rmsprop', loss={'age': 'mse', 'income': 'categorical_crossentropy', 'gender': 'binary_crossentropy'},\n",
    "             loss_weights={'age': 0.25, 'income': 1., 'gender': 10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-76d60660b9b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 다중 출력 모델에 데이터 주입하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mage_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincome_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgender_targets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# age_targets, income_targets, gender_targets가 넘파이 배열이라고 가정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 위와 동일 (출력 층에 이름을 지정했을 때만 사용할 수 있음)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mage_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'income'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mincome_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gender'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgender_targets\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'posts' is not defined"
     ]
    }
   ],
   "source": [
    "# 다중 출력 모델에 데이터 주입하기\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64) # age_targets, income_targets, gender_targets가 넘파이 배열이라고 가정\n",
    "\n",
    "# 위와 동일 (출력 층에 이름을 지정했을 때만 사용할 수 있음)\n",
    "model.fit(posts, {'age': age_targets, 'income': income_targets, 'gender': gender_targets}, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "left_input = Input(shape=(250,250,3))\n",
    "right_input = Input(shape=(250,250,3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케라스 콜백과 텐서보드를 사용한 딥러닝 모델 검사와 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 콜백을 사용하여 모델의 훈련 과정 제어하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    \n",
    "    def set_model(self, model): # 호출하는 모델에 대한 정보를 전달하기 위해 훈련하기 전에 호출\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input, layer_outputs) # 각 층의 활성화 출력을 반환하는 Model 객체\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "            \n",
    "        validation_sample = self.validation_data[0][0:1] # 검증 데이터의 첫 번째 샘플을 가져옴\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        # 배열을 디스크에 저장\n",
    "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'wb')\n",
    "        np.savez(f, activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서보드 소개: 텐서플로의 시각화 프레임워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 텐서보드를 사용한 텍스트 분류 모델\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 2000 # 특성으로 사용할 단어의 수\n",
    "max_len = 500 # 사용할 텍스트의 길이(가장 빈번한 max_features개의 단어만 사용)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len, name='embed'))\n",
    "model.add(layers.Conv1D(32,7,activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32,7,activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "WARNING:tensorflow:From c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:146: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 68s 3ms/step - loss: 0.5947 - acc: 0.6751 - val_loss: 0.8459 - val_acc: 0.6548\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "To visualize embeddings, embeddings_data must be provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-9b8029cd2e0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                          embeddings_freq=1,)] # 1 에포크마다 임베딩 데이터를 기록\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    261\u001b[0m                              \"provided, and cannot be a generator.\")\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_freq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m             raise ValueError(\"To visualize embeddings, embeddings_data must \"\n\u001b[0m\u001b[0;32m    264\u001b[0m                              \"be provided.\")\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: To visualize embeddings, embeddings_data must be provided."
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.TensorBoard(log_dir='my_log_dir', # 로그 파일이 기록될 위치\n",
    "                                         histogram_freq=1, # 1 에포크마다 활성화 출력의 히스토그램을 기록\n",
    "                                         embeddings_freq=1,)] # 1 에포크마다 임베딩 데이터를 기록\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델의 성능을 최대로 끌어올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SeparableConv2D(32,3,activation='relu',input_shape=(height, width, channels,)))\n",
    "model.add(layers.SeparableConv2D(64,3,activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64,3,activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128,3,activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64,3,activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128,3,activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32,activation='relu'))\n",
    "model.add(layers.Dense(num_classes,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
