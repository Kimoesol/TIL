{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 데이터 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 단어와 문자의 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 수준의 원-핫 인코딩하기 (간단한 예)\n",
    "import numpy as np\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "# 초기 데이터: 각 원소가 샘플 (이 예에서 하나의 샘플이 하나의 문장. 하지만 문서 전체가 될 수도 있음)\n",
    "\n",
    "token_index = {} # 데이터에 있는 모든 토큰의 인덱스를 구축함\n",
    "for sample in samples:\n",
    "    for word in sample.split(): # split() 메서드를 사용하여 샘플을 토큰으로 나눔 / 실전에서는 구두점과 특수 문자도 사용함\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1 # 단어마다 고유한 인덱스를 할당 / 인덱스 0은 사용하지 않음\n",
    "            \n",
    "max_length = 10 # 샘플을 벡터로 변환 / 각 샘플에서 max_length까지 단어만 사용\n",
    "\n",
    "results = np.zeros(shape=(len(samples), max_length, max(token_index.values())+1)) # 결과를 저장할 배열\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i,j,index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자 수준의 원-핫 인코딩하기 (간단한 예)\n",
    "import string\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "characters = string.printable # 출력 가능한 모든 아스키(ASCII) 문자\n",
    "token_index = dict(zip(characters, range(1,len(characters)+1)))\n",
    "\n",
    "max_length = 50\n",
    "results = np.zeros((len(samples), max_length, max(token_index.values())+1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample):\n",
    "        index = token_index.get(character)\n",
    "        results[i,j,index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9개의 고유한 토큰을 찾았습니다.\n"
     ]
    }
   ],
   "source": [
    "# 케라스를 사용한 단어 수준의 원-핫 인코딩하기\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=1000) # 가장 빈도가 높은 1,000개의 단어만 선택하도록 Tokenizer 객체를 만듦\n",
    "tokenizer.fit_on_texts(samples) # 단어 인덱스를 구축함\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples) # 문자열을 정수 인덱스의 리스트로 변환\n",
    "\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "# 직접 원-핫 이진 벡터 표현을 얻을 수 있음 / 원-핫 인코딩 외에 다른 벡터화 방법들도 제공\n",
    "\n",
    "word_index = tokenizer.word_index # 계산된 단어 인덱스를 구함\n",
    "print(\"%s개의 고유한 토큰을 찾았습니다.\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해싱 기법을 사용한 단어 수준의 원-핫 인코딩하기 (간단한 예)\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "dimensionality = 1000 # 단어를 크기가 1,000인 벡터로 저장 / 1,000개(또는 그 이상)의 단어가 있다면 해싱 충돌이 늘어나고 인코딩의 정확도가 감소할 것\n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros((len(samples), max_length, dimensionality))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = abs(hash(word)) % dimensionality # 단어를 해싱하여 0과 1,000 사이의 랜덤한 정수 인덱스로 변환\n",
    "        results[i,j,index] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 단어 임베딩 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 층의 객체 생성하기\n",
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(1000, 64) \n",
    "# Embedding 층은 적어도 2개의 매개변수를 받음\n",
    "# 가능한 토큰의 개수 (여기서는 1,000으로 단어 인덱스 최댓값 + 1) / 임베딩 차원 (여기서는 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 층에 사용할 IMDB 데이터 로드하기\n",
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "max_features = 10000 # 특성으로 사용할 단어의 수\n",
    "maxlen = 20 # 사용할 텍스트의 길이(가장 빈번한 max_features개의 단어만 사용)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) # 정수 리스트로 데이터를 로드\n",
    "\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen) # 리스트를 (samples, maxlen) 크기의 2D 정수 텐서로 변환\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 2s 82us/step - loss: 0.6775 - acc: 0.6001 - val_loss: 0.6395 - val_acc: 0.6904\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.5605 - acc: 0.7477 - val_loss: 0.5363 - val_acc: 0.7314\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.4678 - acc: 0.7869 - val_loss: 0.5038 - val_acc: 0.7456\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.4217 - acc: 0.8107 - val_loss: 0.4959 - val_acc: 0.7494\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.3905 - acc: 0.8267 - val_loss: 0.4955 - val_acc: 0.7534\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.3650 - acc: 0.8414 - val_loss: 0.4993 - val_acc: 0.7528\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 74us/step - loss: 0.3423 - acc: 0.8547 - val_loss: 0.5032 - val_acc: 0.7522\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.3216 - acc: 0.8656 - val_loss: 0.5109 - val_acc: 0.7516\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.3030 - acc: 0.8738 - val_loss: 0.5180 - val_acc: 0.7514\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.2850 - acc: 0.8834 - val_loss: 0.5258 - val_acc: 0.7486\n"
     ]
    }
   ],
   "source": [
    "# IMDB 데이터에 Embedding 층과 분류기 사용하기\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "# 나중에 임베딩된 입력을 Flatten 층에서 펼치기 위해 Embedding 층에 input_length를 지정\n",
    "# Embedding 층의 출력 크기는 (samples, maxlen, 8)이 됨\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "\n",
    "model.add(Flatten()) # 3D 임베딩 텐서를 (samples, maxlen*8) 크기의 2D 텐서로 펼침\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid')) # 분류기를 추가\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB 원본 데이터 전처리하기\n",
    "import os\n",
    "\n",
    "imdb_dir = 'c:/datasets/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding='utf8')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88582개의 고유한 토큰을 찾았습니다.\n",
      "데이터 텐서의 크기: (25000, 100)\n",
      "레이블 텐서의 크기: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# IMDB 원본 데이터의 텍스트를 토큰화하기\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100 # 100개 단어 이후는 버림\n",
    "training_samples = 200 # 훈련 샘플은 200개\n",
    "validation_samples = 10000 # 검증 샘플은 1만 개\n",
    "max_words = 10000 # 데이터셋에서 가장 빈도 높은 1만 개의 단어만 사용\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('%s개의 고유한 토큰을 찾았습니다.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "labels = np.asarray(labels)\n",
    "print('데이터 텐서의 크기:', data.shape)\n",
    "print('레이블 텐서의 크기:', labels.shape)\n",
    "\n",
    "# 데이터를 훈련 세트와 검증 세트로 분할 / 샘플이 순서대로 있기 때문에 (부정 샘플이 모두 나온 후 긍정 샘플이 옴) 먼저 데이터를 섞음\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = data[:training_samples]\n",
    "x_val = data[training_samples:training_samples+validation_samples]\n",
    "y_val = labels[training_samples:training_samples+validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000개의 단어 벡터를 찾았습니다.\n"
     ]
    }
   ],
   "source": [
    "# GloVe 단어 임베딩 파일 파싱하기\n",
    "glove_dir = 'c:/datasets/'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('%s개의 단어 벡터를 찾았습니다.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe 단어 임베딩 행렬 준비하기\n",
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector # 임베딩 인덱스에 없는 단어는 모두 0이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의하기\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 훈련된 단어 임베딩을 Embedding 층에 로드하기\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_9 to have shape (1,) but got array with shape (100,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-07ea53a82ff9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pre_trained_glove_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_9 to have shape (1,) but got array with shape (100,)"
     ]
    }
   ],
   "source": [
    "# 훈련과 평가하기\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3de3wU9b3/8deHIGC4ylXlFuwREYqEmCIgtHBEpcVKQXwIxgvSSqm3aluV1rZ66uH36Kn01PqotqWKWk1LPR6hWBVvFbXaowRECyiKyCXgJYACcpGEfH5/zCTZLJtkEzfZzeT9fDz2sTsz35n97mzy3u9+Z/Y75u6IiEh0tUp3BUREpHEp6EVEIk5BLyIScQp6EZGIU9CLiEScgl5EJOIU9C2QmT1hZpemumw6mdkmM5vQCNt1M/u38PHvzOwnyZRtwPMUmNlTDa2nSG1M59E3D2b2acxkNvAZcDic/ra7FzZ9rTKHmW0CvuXuz6R4uw6c6O4bUlXWzHKA94Cj3L0sFfUUqU3rdFdAkuPuHSoe1xZqZtZa4SGZQn+PmUFdN82cmY0zs2Izu9HMPgDuNbNjzOxvZlZiZh+Hj/vErLPczL4VPp5pZv8ws/lh2ffM7KsNLDvAzF4ws71m9oyZ3WlmD9ZQ72TqeKuZvRRu7ykz6x6z/GIz22xmO83splr2z0gz+8DMsmLmTTGzN8LHI8zsn2b2iZm9b2a/MbM2NWzrPjP7z5jp68N1tpvZrLiyk8zsNTPbY2ZbzeyWmMUvhPefmNmnZjaqYt/GrD/azFaY2e7wfnSy+6ae+7mrmd0bvoaPzWxJzLLJZrY6fA3vmtnEcH61bjIzu6XifTaznLAL65tmtgX4ezj/f8L3YXf4NzIkZv2jzeyX4fu5O/wbO9rMHjOzq+Nezxtm9o1Er1VqpqCPhmOBrkB/YDbB+3pvON0POAD8ppb1TwPWA92BXwD3mJk1oOyfgFeBbsAtwMW1PGcydbwQuAzoCbQBfgBgZoOB34bbPz58vj4k4O7/B+wD/j1uu38KHx8GrgtfzyjgDOCKWupNWIeJYX3OBE4E4o8P7AMuAboAk4DvxATUl8P7Lu7ewd3/GbftrsBjwB3ha/tv4DEz6xb3Go7YNwnUtZ8fIOgKHBJu61dhHUYAfwSuD1/Dl4FNNe2PBL4CnAycHU4/QbCfegKrgNiuxvnAqcBogr/jG4By4H7goopCZjYM6A08Xo96CIC769bMbgT/cBPCx+OAQ0C7WsrnAh/HTC8n6PoBmAlsiFmWDThwbH3KEoRIGZAds/xB4MEkX1OiOv44ZvoKYFn4+KfAophl7cN9MKGGbf8nsDB83JEghPvXUPZaYHHMtAP/Fj6+D/jP8PFC4Ocx5QbGlk2w3duBX4WPc8KyrWOWzwT+ET6+GHg1bv1/AjPr2jf12c/AcQSBekyCcr+vqG9tf3/h9C0V73PMazuhljp0Cct0JvggOgAMS1CuLbCL4LgHBB8IdzX1/1sUbmrRR0OJux+smDCzbDP7ffhVeA9BV0GX2O6LOB9UPHD3/eHDDvUsezywK2YewNaaKpxkHT+Iebw/pk7Hx27b3fcBO2t6LoLW+1QzawtMBVa5++awHgPD7owPwnr8P4LWfV2q1QHYHPf6TjOz58Iuk93AnCS3W7HtzXHzNhO0ZivUtG+qqWM/9yV4zz5OsGpf4N0k65tI5b4xsywz+3nY/bOHqm8G3cNbu0TP5e6fAQ8BF5lZK2AGwTcQqScFfTTEnzr1feAk4DR370RVV0FN3TGp8D7Q1cyyY+b1raX856nj+7HbDp+zW02F3X0dQVB+lerdNhB0Ab1F0GrsBPyoIXUg+EYT60/AUqCvu3cGfhez3bpOddtO0NUSqx+wLYl6xattP28leM+6JFhvK/CFGra5j+DbXIVjE5SJfY0XApMJurc6E7T6K+qwAzhYy3PdDxQQdKnt97huLkmOgj6aOhJ8Hf4k7O+9ubGfMGwhFwG3mFkbMxsFfL2R6vgwcI6ZjQkPnP6Muv+W/wRcQxB0/xNXjz3Ap2Y2CPhOknV4CJhpZoPDD5r4+nckaC0fDPu7L4xZVkLQZXJCDdt+HBhoZheaWWszuwAYDPwtybrF1yPhfnb39wn6zu8KD9oeZWYVHwT3AJeZ2Rlm1srMeof7B2A1MD0snw9MS6IOnxF868om+NZUUYdygm6w/zaz48PW/6jw2xdhsJcDv0St+QZT0EfT7cDRBK2l/wOWNdHzFhAc0NxJ0C/+F4J/8EQaXEd3XwtcSRDe7wMfA8V1rPZnguMZf3f3HTHzf0AQwnuBP4R1TqYOT4Sv4e/AhvA+1hXAz8xsL8ExhYdi1t0PzANesuBsn5Fx294JnEPQGt9JcHDynLh6J6uu/XwxUErwreYjgmMUuPurBAd7fwXsBp6n6lvGTwha4B8D/0H1b0iJ/JHgG9U2YF1Yj1g/AP4FrCDok/8vqmfTH4GhBMd8pAH0gylpNGb2F+Atd2/0bxQSXWZ2CTDb3cekuy7NlVr0kjJm9iUz+0L4VX8iQb/skrrWE6lJ2C12BbAg3XVpzhT0kkrHEpz69ynBOeDfcffX0lojabbM7GyC4xkfUnf3kNRCXTciIhGnFr2ISMRl5KBm3bt395ycnHRXQ0Sk2Vi5cuUOd++RaFlGBn1OTg5FRUXproaISLNhZvG/pq6krhsRkYhT0IuIRJyCXkQk4jKyjz6R0tJSiouLOXjwYN2Fpcm1a9eOPn36cNRRR6W7KiISp9kEfXFxMR07diQnJ4ear4kh6eDu7Ny5k+LiYgYMGJDu6ohInGbTdXPw4EG6deumkM9AZka3bt30bUukgQoLIScHWrUK7gsL61qjfppNix5QyGcwvTciDVNYCLNnw/7wkj2bNwfTAAUFqXmOZtOiFxGJoptuqgr5Cvv3B/NTRUGfhJ07d5Kbm0tubi7HHnssvXv3rpw+dOhQresWFRVxzTXX1Pkco0ePTlV1RaQZ2bKlfvMbIrJBn8o+r27durF69WpWr17NnDlzuO666yqn27RpQ1lZWY3r5ufnc8cdd9T5HC+//HLDKygizVa/+ItQ1jG/ISIZ9BV9Xps3g3tVn1cqD3DMnDmT733ve4wfP54bb7yRV199ldGjRzN8+HBGjx7N+vXrAVi+fDnnnHMOALfccguzZs1i3LhxnHDCCdU+ADp06FBZfty4cUybNo1BgwZRUFBAxQijjz/+OIMGDWLMmDFcc801lduNtWnTJsaOHUteXh55eXnVPkB+8YtfMHToUIYNG8bcuXMB2LBhAxMmTGDYsGHk5eXx7ruf53rQIlJf8+ZBdnb1ednZwfyUcfeMu5166qkeb926dUfMq0n//u5BxFe/9e+f9CZqdPPNN/ttt93ml156qU+aNMnLysrc3X337t1eWlrq7u5PP/20T5061d3dn3vuOZ80aVLluqNGjfKDBw96SUmJd+3a1Q8dOuTu7u3bt68s36lTJ9+6dasfPnzYR44c6S+++KIfOHDA+/Tp4xs3bnR39+nTp1duN9a+ffv8wIED7u7+9ttve8W+fPzxx33UqFG+b98+d3ffuXOnu7uPGDHCH3nkEXd3P3DgQOXyhqjPeyQiVR58MMgns+D+wQfrvw2gyGvI1GZ11k2ymqLPC+D8888nKysLgN27d3PppZfyzjvvYGaUlpYmXGfSpEm0bduWtm3b0rNnTz788EP69OlTrcyIESMq5+Xm5rJp0yY6dOjACSecUHme+owZM1iw4MiL7pSWlnLVVVexevVqsrKyePvttwF45plnuOyyy8gOmw5du3Zl7969bNu2jSlTpgDBj55EWpLCwuCg55YtQVfJvHmpO9OlPgoKGvd5I9l10xR9XgDt27evfPyTn/yE8ePHs2bNGh599NEazylv27Zt5eOsrKyE/fuJyniSF4j51a9+Ra9evXj99dcpKiqqPFjs7kecApnsNkWiqCm6eDNFJIO+Sfq84uzevZvevXsDcN9996V8+4MGDWLjxo1s2rQJgL/85S811uO4446jVatWPPDAAxw+fBiAs846i4ULF7I/PI9r165ddOrUiT59+rBkSXBZ188++6xyuUjUNcVpjZkikkFfUAALFkD//mAW3C9Y0LhfjW644QZ++MMfcvrpp1eGayodffTR3HXXXUycOJExY8bQq1cvOnfufES5K664gvvvv5+RI0fy9ttvV37rmDhxIueeey75+fnk5uYyf/58AB544AHuuOMOTjnlFEaPHs0HH3yQ8rqLZKKm6uLNBBl5zdj8/HyPv/DIm2++ycknn5ymGmWGTz/9lA4dOuDuXHnllZx44olcd9116a5WJb1H0pzk5ATdNfH694fwi3OzYmYr3T0/0bJItuij6g9/+AO5ubkMGTKE3bt38+1vfzvdVRJpttLRxZsuCvpmpOKHWuvWraOwsLDyDBqR5qixB/KqSzq6eNMlkqdXikhma4qBvJLR2Kc1Zgq16EWkybWkM14ygYJeRJpcSzrjJRMo6EWkyTXVjxoloKBP0rhx43jyySerzbv99tu54ooral2n4jTRr33ta3zyySdHlLnlllsqz2mvyZIlS1i3bl3l9E9/+lOeeeaZ+lRfJKO0pDNeMoGCPkkzZsxg0aJF1eYtWrSIGTNmJLX+448/TpcuXRr03PFB/7Of/YwJEyY0aFsimaAlnfGSCRT0SZo2bRp/+9vf+Oyzz4BgOODt27czZswYvvOd75Cfn8+QIUO4+eabE66fk5PDjh07AJg3bx4nnXQSEyZMqBzOGILz5L/0pS8xbNgwzjvvPPbv38/LL7/M0qVLuf7668nNzeXdd99l5syZPPzwwwA8++yzDB8+nKFDhzJr1qzK+uXk5HDzzTeTl5fH0KFDeeutt46ok4Y0bpnSfVpjhYKC4IdJ5eXBvUK+8TTL0yuvvRZWr07tNnNz4fbba17erVs3RowYwbJly5g8eTKLFi3iggsuwMyYN28eXbt25fDhw5xxxhm88cYbnHLKKQm3s3LlShYtWsRrr71GWVkZeXl5nHrqqQBMnTqVyy+/HIAf//jH3HPPPVx99dWce+65nHPOOUybNq3atg4ePMjMmTN59tlnGThwIJdccgm//e1vufbaawHo3r07q1at4q677mL+/Pncfffd1dbv2bMnTz/9NO3ateOdd95hxowZFBUV8cQTT7BkyRJeeeUVsrOz2bVrFwAFBQXMnTuXKVOmcPDgQcrLyxu0ryV9MuW0RmlaatHXQ2z3TWy3zUMPPUReXh7Dhw9n7dq11bpZ4r344otMmTKF7OxsOnXqxLnnnlu5bM2aNYwdO5ahQ4dSWFjI2rVra63P+vXrGTBgAAMHDgTg0ksv5YUXXqhcPnXqVABOPfXUysHQYpWWlnL55ZczdOhQzj///Mp6JzuksX6w1fzotMaWKakWvZlNBH4NZAF3u/vP45Z3Bh4E+oXbnO/u94bLNgF7gcNAWU1jMdRHbS3vxvSNb3yD733ve6xatYoDBw6Ql5fHe++9x/z581mxYgXHHHMMM2fOrHGI4grxwwVXmDlzJkuWLGHYsGHcd999LF++vNbt1DVOUcVwxzUNhxw7pHF5eXnlePQa0ji6dFpjy1Rni97MsoA7ga8Cg4EZZjY4rtiVwDp3HwaMA35pZm1ilo9399xUhHw6dejQgXHjxjFr1qzK1vyePXto3749nTt35sMPP+SJJ56odRtf/vKXWbx4MQcOHGDv3r08+uijlcv27t3LcccdR2lpKYUxHacdO3Zk7969R2xr0KBBbNq0iQ0bNgDBSJRf+cpXkn49GtK45dFpjS1TMl03I4AN7r7R3Q8Bi4DJcWUc6GhBM7ADsAuo+YrZzdiMGTN4/fXXmT59OgDDhg1j+PDhDBkyhFmzZnH66afXun5eXh4XXHABubm5nHfeeYwdO7Zy2a233sppp53GmWeeyaBBgyrnT58+ndtuu43hw4dXOwDarl077r33Xs4//3yGDh1Kq1atmDNnTtKvRUMatzw6rbFlqnOYYjObBkx092+F0xcDp7n7VTFlOgJLgUFAR+ACd38sXPYe8DHBh8Hv3f3I69/F0TDFzZPeo+YhUy6fJ6lV2zDFyfTRJ+pQjv90OBtYDfw78AXgaTN70d33AKe7+3Yz6xnOf8vdX4hbHzObDcwG6KfvkSKNpqUM5CVVkum6KQb6xkz3AbbHlbkMeCS8GPkG4D2C1j3uvj28/whYTNAVdAR3X+Du+e6e36NHj/q9ChERqVEyQb8CONHMBoQHWKcTdNPE2gKcAWBmvYCTgI1m1j7s1sHM2gNnAWsaWlmd+ZG59N6IZK46g97dy4CrgCeBN4GH3H2tmc0xs4ojf7cCo83sX8CzwI3uvgPoBfzDzF4HXgUec/dlDalou3bt2LlzpwIlA7k7O3furDw9UxLLlF+kSsvTbK4ZW1paSnFxcZ3nqEt6tGvXjj59+nDUUUeluyoZKf4XqRCc7aLxXSRVajsY22yCXqQ5i9qFqCXz6OLgImmmX6RKOinoRZqAfpEq6aSgF2kC+kWqpJOCXqQJ6EIbkk7Ncjx6keZIv0iVdFGLXkQk4hT0IiIRp6CXyNMvUqWlUx+9RJqukSqiFr1EnK6RKqKgl4jTL1JFFPQScfpFqoiCXiJOv0gVUdBLxOkXqSI660ZaAP0iVVo6tehFRCJOQS8iEnEKehGRiFPQS6PR0AMimUEHY6VRaOgBkcyhFr00Cg09IJI5FPTSKDT0gEjmUNBLo9DQAyKZQ0EvjUJDD4hkDgW9NAoNPSCSOZIKejObaGbrzWyDmc1NsLyzmT1qZq+b2VozuyzZdSW6Cgpg0yYoLw/uFfIi6VFn0JtZFnAn8FVgMDDDzAbHFbsSWOfuw4BxwC/NrE2S64qISCNKpkU/Atjg7hvd/RCwCJgcV8aBjmZmQAdgF1CW5LoiItKIkgn63sDWmOnicF6s3wAnA9uBfwHfdffyJNcFwMxmm1mRmRWVlJQkWX0REalLMkFvCeZ53PTZwGrgeCAX+I2ZdUpy3WCm+wJ3z3f3/B49eiRRLRERSUYyQV8M9I2Z7kPQco91GfCIBzYA7wGDklxXREQaUTJBvwI40cwGmFkbYDqwNK7MFuAMADPrBZwEbExyXRERaUR1Dmrm7mVmdhXwJJAFLHT3tWY2J1z+O+BW4D4z+xdBd82N7r4DING6jfNSREQkEXNP2GWeVvn5+V5UVJTuaoiINBtmttLd8xMt0y9jRUQiTkEfQbrgh4jE0oVHIkYX/BCReGrRR4wu+CEi8RT0EaMLfohIPAV9xOiCHyIST0EfMbrgh4jEU9BHjC74ISLxdNZNBBUUKNhFpIpa9CIiEaegFxGJOAW9iEjEKehFRCJOQS8iEnEKehGRiFPQi4hEnIJeRCTiFPQiIhGnoBcRiTgFvYhIxCnoRUQiTkEvIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIRl9QVpsxsIvBrIAu4291/Hrf8eqDimkatgZOBHu6+y8w2AXuBw0CZu+enqO4iABw4ACUlVbePPqo+XXHbvx9at4asrCNv6Zqfjudu1Sq4zKS0HHUGvZllAXcCZwLFwAozW+ru6yrKuPttwG1h+a8D17n7rpjNjHf3HSmtuUTWvn21B3b8sn37Em+ndWvo0SO49ewJvXrB4cNQVhbcV9xKS+HgwSPnV9zqO785aNUqcz70zGq+VXwoNfSW7PqtW0OnTtC5c3CLf9y6mV90NZnqjwA2uPtGADNbBEwG1tVQfgbw59RUr/kpLISbboItW6BfP5g3r2Vfv9Ud9u5NLrArbgcOJN5W27ZVwd2jBwwcWD3IY5f16BH8kzZ1y9UdystT84GRqvlN8Ryffdbw7bjXfisvTzy/KbVvXz38E30g1DWvXbumrXOsZIK+N7A1ZroYOC1RQTPLBiYCV8XMduApM3Pg9+6+oIZ1ZwOzAfr165dEtTJPYSHMnh10EQBs3hxMQ3TC/uBB2LGj9ltJSfXpQ4cSb+voo6sH85AhR4Z17K1jx8zvcjCraqlK42voh0T8rbQ0aJDs3l39tmdPzfO2bKmaV/E/X5s2ber+QOjRA66+OvX7ybyOj0YzOx84292/FU5fDIxw9yOqY2YXABe5+9dj5h3v7tvNrCfwNHC1u79Q23Pm5+d7UVFR/V9NmuXkBOEer39/2LSpqWtTt7Iy2LmzfqFdUzcJQNeu0L174luilnf79k33WkUaU1lZ9Q+F2j4gapq3Zw8cdxxs29awOpjZypqOgSbToi8G+sZM9wG211B2OnHdNu6+Pbz/yMwWE3QF1Rr0zdWWLfWb35jefRdefDHoGqkpuD/5pOb1O3asCumePWHw4KrAThTkxxzT/PsxRRqqdeugodO1a8O3UV5ec7fl55XMv+YK4EQzGwBsIwjzC+MLmVln4CvARTHz2gOt3H1v+Pgs4GepqHgm6tcvcYu+KXqiDh2Cf/wDHnssuK1fX7Wsom+7IqgHDKi55d29O3TrFqwjIk2nVavG+5ZbZ9C7e5mZXQU8SXB65UJ3X2tmc8LlvwuLTgGecvfYL/e9gMUWdKy2Bv7k7stS+QIyybx51fvoAbKzg/mN4YMP4IkngmB/6qmgj7FNGxg3Dq64As46C/r2DeqQ6X3bItJ46uyjT4fm2kcPjXvWTXk5rFxZ1Wqv2EXHHw+TJgW3M86ADh1S83wi0nzU1kevoM9we/YErfXHHgta7x9+GLTOR46sCvdhw9RiF2npPu/BWGlC7kH/ekWr/cUXgyP6XbrAxIlBsE+cGPSli4gkQ0GfAQ4ehOefrwr3jRuD+V/8Inz/+0G4jxqls1pEpGEUHWmybVtVsD/zTHAAt127oI/9Bz+Ar30tOP9eROTzUtA3kcOH4ZVXqsL99deD+f37w8yZQat9/Pjg16IiIqmkoG9Eu3bBk08Gwb5sWfAr1KwsOP10+K//CsJ98GAdSBWRxqWgT7FDh+DOO2HxYnjppeCUyO7dg66YSZOCc9uPOSbdtRSRlkRBn0IffwznnQfPPQfDh8OPfhSE+5e+pEGuRCR9FPQp8s47cM45weBlf/wjXHxxumskIhJQ0KfA88/D1KlBX/uzz8KYMemukYhIFV0z9nO6914488xghMdXXlHIi0jmUdA3UHk5zJ0Ls2YFg4j985/whS+ku1YiIkdS100D7NsX9MEvXgxz5sAdd8BRR6W7ViIiiSno62n7djj3XHjtNbj9drjmGp0HLyKZTUFfD6tWBSG/ezcsXRqcOikikunUR5+kv/4Vxo4NrgLz0ksKeRFpPhT0dXCH+fNhypRgNMlXX4VTTkl3rUREkqegr8WhQ3D55XD99TBtGixfDscem+5aiYjUj4K+Brt2BRf4uOce+PGPYdEijSwpIs2TDsYmoOEMRCRKFPRxli8PhjPIytJwBiISDeq6iXHvvcEwwr16aTgDEYkOBT3BcAY33lh9OIMTTkh3rUREUqPFd91oOAMRiboWHfTbtgW/dF29WsMZiEh0tdigX7UKvv512LNHwxmISLQl1UdvZhPNbL2ZbTCzuQmWX29mq8PbGjM7bGZdk1k3HZYsCYYzyMrScAYiEn11Br2ZZQF3Al8FBgMzzGxwbBl3v83dc909F/gh8Ly770pm3abkDrfdFpw+qeEMRKSlSKZFPwLY4O4b3f0QsAiYXEv5GcCfG7huozl0CL71LbjhBg1nICItSzJB3xvYGjNdHM47gpllAxOB/23AurPNrMjMikpKSpKoVvJ27YKzz4aFCzWcgYi0PMkEfaLzULyGsl8HXnL3XfVd190XuHu+u+f36NEjiWol5513YORIePnlYDiDW28NhhoWEWkpkjnrphjoGzPdB9heQ9npVHXb1HfdlNNwBiIiybXoVwAnmtkAM2tDEOZL4wuZWWfgK8Bf67tuY1i4EM48U8MZiIjUGfTuXgZcBTwJvAk85O5rzWyOmc2JKToFeMrd99W1bipfQLyK4Qy++U0YP17DGYiImHtN3e3pk5+f70VFRfVeb98+uOii4Dx5DWcgIi2Jma109/xEyyLzy9iPP4YJEzScgYhIvMicf9K5c/AjqKVL4bvfVciLiFSITIu+VSu4//5010JEJPNEpkUvIiKJKehFRCJOQS8iEnEKehGRiFPQi4hEnIJeRCTiFPQiIhGnoBcRiTgFvYhIxCnoRUQiTkEvIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIk5BLyIScQp6EZGIU9CLiEScgl5EJOIU9CIiEZdU0JvZRDNbb2YbzGxuDWXGmdlqM1trZs/HzN9kZv8KlxWlquIiIpKc1nUVMLMs4E7gTKAYWGFmS919XUyZLsBdwER332JmPeM2M97dd6Sw3iIikqRkWvQjgA3uvtHdDwGLgMlxZS4EHnH3LQDu/lFqqykiIg2VTND3BrbGTBeH82INBI4xs+VmttLMLolZ5sBT4fzZNT2Jmc02syIzKyopKUm2/iIiUoc6u24ASzDPE2znVOAM4Gjgn2b2f+7+NnC6u28Pu3OeNrO33P2FIzbovgBYAJCfnx+/fRERaaBkWvTFQN+Y6T7A9gRllrn7vrAv/gVgGIC7bw/vPwIWE3QFiYhIE0km6FcAJ5rZADNrA0wHlsaV+Ssw1sxam1k2cBrwppm1N7OOAGbWHjgLWJO66ouISF3q7Lpx9zIzuwp4EsgCFrr7WjObEy7/nbu/aWbLgDeAcuBud19jZicAi82s4rn+5O7LGuvFiIjIkcw987rD8/PzvahIp9yLiCTLzFa6e36iZfplrIhIxCnoRUQiTkEvIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIk5BLyIScQp6EZGIU9CLiEScgl5EJOIU9CIiEaegFxGJOAW9iEjEKehFRCJOQS8iEnEKehGRiFPQi4hEnIJeRCTiFPQiIhGnoBcRiTgFvYhIxCnoRUQiLqmgN7OJZrbezDaY2dwayowzs9VmttbMnq/PuqlQWAg5OdCqVXBfWNhYzyQi0ry0rquAmWUBdwJnAsXACjNb6u7rYsp0Ae4CJrr7FjPrmey6qVBYCLNnw/79wfTmzcE0QO1K/CEAAARSSURBVEFBKp9JRKT5SaZFPwLY4O4b3f0QsAiYHFfmQuARd98C4O4f1WPdz+2mm6pCvsL+/cF8EZGWLpmg7w1sjZkuDufFGggcY2bLzWylmV1Sj3UBMLPZZlZkZkUlJSXJ1T60ZUv95ouItCTJBL0lmOdx062BU4FJwNnAT8xsYJLrBjPdF7h7vrvn9+jRI4lqVenXr37zRURakmSCvhjoGzPdB9ieoMwyd9/n7juAF4BhSa77uc2bB9nZ1edlZwfzRURaumSCfgVwopkNMLM2wHRgaVyZvwJjzay1mWUDpwFvJrnu51ZQAAsWQP/+YBbcL1igA7EiIpDEWTfuXmZmVwFPAlnAQndfa2ZzwuW/c/c3zWwZ8AZQDtzt7msAEq3bGC+koEDBLiKSiLkn7DJPq/z8fC8qKkp3NUREmg0zW+nu+YmW6ZexIiIRp6AXEYk4Bb2ISMQp6EVEIi4jD8aaWQmwOd31+Jy6AzvSXYkMoX1RnfZHddofVT7Pvujv7gl/bZqRQR8FZlZU0xHwlkb7ojrtj+q0P6o01r5Q142ISMQp6EVEIk5B33gWpLsCGUT7ojrtj+q0P6o0yr5QH72ISMSpRS8iEnEKehGRiFPQp5CZ9TWz58zszfAi6d9Nd53SzcyyzOw1M/tbuuuSbmbWxcweNrO3wr+RUemuUzqZ2XXh/8kaM/uzmbVLd52akpktNLOPzGxNzLyuZva0mb0T3h+TiudS0KdWGfB9dz8ZGAlcaWaD01yndPsuwbUJBH5NcIGeQQQX5mmx+8XMegPXAPnu/kWCYcynp7dWTe4+YGLcvLnAs+5+IvBsOP25KehTyN3fd/dV4eO9BP/ICa+R2xKYWR+Cy0vene66pJuZdQK+DNwD4O6H3P2T9NYq7VoDR5tZayCbRrj6XCZz9xeAXXGzJwP3h4/vB76RiudS0DcSM8sBhgOvpLcmaXU7cAPBxWhauhOAEuDesCvrbjNrn+5KpYu7bwPmA1uA94Hd7v5UemuVEXq5+/sQNByBnqnYqIK+EZhZB+B/gWvdfU+665MOZnYO8JG7r0x3XTJEayAP+K27Dwf2kaKv5c1R2Pc8GRgAHA+0N7OL0lur6FLQp5iZHUUQ8oXu/ki665NGpwPnmtkmYBHw72b2YHqrlFbFQLG7V3zDe5gg+FuqCcB77l7i7qXAI8DoNNcpE3xoZscBhPcfpWKjCvoUMjMj6IN9093/O931SSd3/6G793H3HIKDbH939xbbYnP3D4CtZnZSOOsMYF0aq5RuW4CRZpYd/t+cQQs+OB1jKXBp+PhS4K+p2GidFweXejkduBj4l5mtDuf9yN0fT2OdJHNcDRSaWRtgI3BZmuuTNu7+ipk9DKwiOFvtNVrYUAhm9mdgHNDdzIqBm4GfAw+Z2TcJPgzPT8lzaQgEEZFoU9eNiEjEKehFRCJOQS8iEnEKehGRiFPQi4hEnIJeRCTiFPQiIhH3/wG96EQNqMedpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 그래프 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc =history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_7 to have shape (1,) but got array with shape (100,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-435fbbc0b652>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rladh\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_7 to have shape (1,) but got array with shape (100,)"
     ]
    }
   ],
   "source": [
    "# 사전 훈련된 단어 임베딩을 사용하지 않고 같은 모델 훈련하기\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 토큰화하기\n",
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding='utf8')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "                \n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트에서 모델 평가하기\n",
    "model.load_weights('pre_trained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
